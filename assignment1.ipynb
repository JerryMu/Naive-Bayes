{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `Pengyu Mu, Ziyuan Xiao`\n",
    "\n",
    "**Student ID(s):**     `890756, 940448`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read all datasets \n",
    "adult = pd.read_csv(\"datasets/adult.data\", header = None)\n",
    "bank = pd.read_csv(\"datasets/bank.data\", header = None)\n",
    "breast_cancer_wisconsin = pd.read_csv(\"datasets/breast-cancer-wisconsin.data\", header = None)\n",
    "car = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "lymphography = pd.read_csv(\"datasets/lymphography.data\", header = None)\n",
    "mushroom = pd.read_csv(\"datasets/mushroom.data\", header = None)\n",
    "nursery = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "somerville = pd.read_csv(\"datasets/somerville.data\", header = None)\n",
    "university = pd.read_csv(\"datasets/university.data\", header = None)\n",
    "wdbc = pd.read_csv(\"datasets/wdbc.data\", header = None)\n",
    "wine = pd.read_csv(\"datasets/wine.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function that delete all missing values\n",
    "def delete_missing_value(raw_dataset, missing_values):\n",
    "    rows = set(raw_dataset[raw_dataset.values == missing_values].index)\n",
    "    data = raw_dataset.drop(index = rows)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "preprocess dataset incluse delete all missing values and delete ID column from dataset\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(df, missing_values, id_column = None):\n",
    "    train = delete_missing_value(df, missing_values)\n",
    "    if id_column != None:\n",
    "        train = train.drop(columns = [id_column])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Global Variables that help code run take adult dataset as an example\n",
    "    index column that need to be remove\n",
    "    Assign None to id_column means no id column\n",
    "    Edit if change dataset\n",
    "'''\n",
    "id_column = None\n",
    "# Missing Value that should be delete\n",
    "missing_values = '?'\n",
    "'''\n",
    "preprocessing data \n",
    "1. delete missing value \n",
    "\n",
    "2. delete id column\n",
    "'''\n",
    "train_data = preprocess(adult, missing_values,id_column)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "\n",
    "# Enter type of datasets\n",
    "\n",
    "datasets_types = \"MIX\"\n",
    "\n",
    "'''\n",
    "    0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "    Only works when dataset_types is MIX\n",
    "'''\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "'''\n",
    "    row of class index\n",
    "    for example: adult Class: last column (15) \n",
    "    class_column should be 14\n",
    "'''\n",
    "class_column = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape =====> (30162, 15)\n",
      "======================================================\n",
      "EPSILON ========> 1.657715005636231e-05\n",
      "======================================================\n",
      "Some Data Examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "\n",
       "                  6              7      8     9     10  11  12             13  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male  2174   0  40  United-States   \n",
       "1    Exec-managerial        Husband  White  Male     0   0  13  United-States   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male     0   0  40  United-States   \n",
       "\n",
       "      14  \n",
       "0  <=50K  \n",
       "1  <=50K  \n",
       "2  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Data Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      int64\n",
       "1     object\n",
       "2      int64\n",
       "3     object\n",
       "4      int64\n",
       "5     object\n",
       "6     object\n",
       "7     object\n",
       "8     object\n",
       "9     object\n",
       "10     int64\n",
       "11     int64\n",
       "12     int64\n",
       "13    object\n",
       "14    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#value caculate from global variable \n",
    "\n",
    "#use epsilon smooth\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "#list of all features columns name\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "# Show some useful information about the data\n",
    "print(\"Data Shape =====>\", train_data.shape)\n",
    "print(\"======================================================\")\n",
    "print(\"EPSILON ========>\", EPSILON)\n",
    "print(\"======================================================\")\n",
    "print(\"Some Data Examples:\")\n",
    "display(train_data.head(3))\n",
    "print(\"======================================================\")\n",
    "print(\"Data Type:\")\n",
    "display(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate prior\n",
    "def find_nominal_prob(class_column):\n",
    "    prior = {}\n",
    "    total_number = len(class_column)\n",
    "    classes = class_column.value_counts()\n",
    "    for key in classes.keys():\n",
    "        prior[key] = np.log2(classes[key]/total_number)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<=50K': -0.4129662865089241, '>50K': -2.0062315395856487}\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior\n",
    "print(find_nominal_prob(train_data[class_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nominal_llh(attributes, llh_dict, data, feature_row):\n",
    "    #calculate nominal llh save llh as a 2d dictionary\n",
    "    all_feature = data[feature_row].value_counts()\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature_row:{}}\n",
    "        subset = data[data[class_column] == attribute][feature_row]\n",
    "        feature_dict[feature_row] = find_nominal_prob(subset)\n",
    "        for check_feature in all_feature.keys():\n",
    "            if check_feature not in feature_dict[feature_row].keys():\n",
    "                feature_dict[feature_row][check_feature] = np.log2(EPSILON)\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "            \n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_numerical_llh(attributes, llh_dict, data, feature):\n",
    "#  Save mean and Std as llh\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature:{}}\n",
    "        subset = subset = data[data[class_column] == attribute][feature]\n",
    "        mean = np.mean(subset)\n",
    "        std = np.std(subset)\n",
    "        feature_dict[feature][\"mean\"] = mean\n",
    "        feature_dict[feature][\"std\"] = std\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function should calculat prior probabilities and likelihoods from the training data\n",
    "#  and using them to build a naive Bayes model\n",
    "\n",
    "def train(data):\n",
    "    prior = find_nominal_prob(data[class_column])\n",
    "    llh_dict = dict.fromkeys(prior)\n",
    "    for i in feature_columns:\n",
    "        if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "            find_numerical_llh(prior, llh_dict, data, i)\n",
    "        else:\n",
    "            find_nominal_llh(prior, llh_dict, data, i)\n",
    "            \n",
    "    return prior, llh_dict\n",
    "\n",
    "prior, llh_dict = train(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function should predict classes for new items in\n",
    "a test dataset(for the purposes of this assignment, you\n",
    "can re-use the training data as a test set)\n",
    "'''\n",
    "\n",
    "def predict(instance, prior, llh_dict):\n",
    "    all_prob = {}\n",
    "    for attribute in prior.keys():\n",
    "        all_prob[attribute] = prior[attribute]\n",
    "        for i in feature_columns:\n",
    "            prob = 0\n",
    "            if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "                mean = max(llh_dict[attribute][i][\"mean\"], 1 * 10 ** -8)\n",
    "                std = max(llh_dict[attribute][i][\"std\"], 1 * 10 ** -8)\n",
    "                prob = stats.norm.pdf(x=instance[i], loc=mean, scale=std)\n",
    "                if prob > 0.0:\n",
    "                    prob = np.log2(prob)\n",
    "                else:\n",
    "                    prob = np.log2(1 * 10 ** -8)\n",
    "            else:\n",
    "                prob = llh_dict[attribute][i][instance[i]]\n",
    "            all_prob[attribute] += prob\n",
    "            \n",
    "    max_prob = -10000\n",
    "    max_key = \"\"\n",
    "    \n",
    "    for prob in all_prob.keys():\n",
    "        if(all_prob[prob] > max_prob):\n",
    "            max_prob = all_prob[prob]\n",
    "            max_key = prob\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<=50K'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of the prediction working\n",
    "predict(train_data.iloc[0], prior, llh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function should evaliate the prediction performance by comparing your\n",
    "model’s class outputs to ground truth labels\n",
    "'''\n",
    "def evaluate(data, prior, llh_dict, interesting_class = None):\n",
    "    predict_list = []\n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "    result = {}\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    # make confusion matrix\n",
    "    for index, row in data.iterrows():\n",
    "        actual_class = row[class_column]\n",
    "        predict_class = predict(row, prior, llh_dict)\n",
    "        if (actual_class == predict_class):\n",
    "            correct += 1\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    TP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    TN += 1\n",
    "        else:\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    FP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    FN += 1\n",
    "                    \n",
    "    correct_rate = correct/total\n",
    "    result[\"correct_rate\"] = correct_rate\n",
    "    if (interesting_class):\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        result[\"precision\"] = precision\n",
    "        result[\"recall\"] = recall\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "A helper fuction for later use\n",
    "This function could quickly calculate the result\n",
    "For this assignment dafult train_data is test_data \n",
    "'''\n",
    "def calc_outcome(train_data, test_data = None, interesting_class = None):\n",
    "    data_train_prior, data_llh_dict = train(train_data)\n",
    "    if test_data is None:\n",
    "        test_data = train_data\n",
    "    data_eval = evaluate(test_data, data_train_prior,data_llh_dict, interesting_class)\n",
    "    return data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Overall Accuracy is: \n",
      "{'correct_rate': 0.821928254094556, 'precision': 0.9315794120243666, 'recall': 0.8467001003009027}\n"
     ]
    }
   ],
   "source": [
    "# An example of using calc_outcome set interesting class as \"<=50K\"\n",
    "print(\"======================================================\")\n",
    "print(\"Overall Accuracy is: \")\n",
    "print(calc_outcome(train_data, interesting_class = \"<=50K\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the na¨ıve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian na¨ıve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use adult dataset for this question\n",
    "index column that need to be remove\n",
    "Assign None to id_column means no id column\n",
    "'''\n",
    "id_column = None\n",
    "\n",
    "#  Enter dataset here\n",
    "missing_values = '?'\n",
    "train_data = preprocess(adult, missing_values,id_column)\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "\n",
    "# Enter type of datasets\n",
    "datasets_types = \"MIX\"\n",
    "\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "# Only works when dataset_types is MIX\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "class_column = 14\n",
    "\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# divide class label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "\n",
    "def discretise(data,levels,by):\n",
    "    '''Given a data set and its corresponding data type,\n",
    "    All its features must be discretized into discrete features，\n",
    "    Takes an integer, then determine the total number of discrete feature levels'''\n",
    "\n",
    "    copy_data = data.copy()\n",
    "    for i in feature_columns:\n",
    "        '''Find out all the Numeric Data, and then form a new DataFrame\n",
    "           Note: 2 means numeric data type'''\n",
    "        if datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2): \n",
    "            feature = data[i]\n",
    "            copy_feature = feature.copy()\n",
    "            \n",
    "            # Equal Width\n",
    "            if by =='width':\n",
    "                '''\n",
    "                After finding maximum and minimux,\n",
    "                calculate the width of each level\n",
    "                '''\n",
    "                maximum = np.max(feature)\n",
    "                minimum = np.min(feature)\n",
    "                width = (maximum-minimum)/levels\n",
    "                # Assign the corresponding level label to the corresponding instance \n",
    "                for j in range(levels):\n",
    "                    copy_feature[feature<=(maximum-width*j)] = ('category'+str(levels-j))\n",
    "           \n",
    "            # Equal Frequency\n",
    "            else:\n",
    "                # Calculate the frequency of each level\n",
    "                frequency = feature.shape[0]/levels \n",
    "                for m in range(levels):\n",
    "                    # find out the lower bound of index\n",
    "                    lower = int(frequency*m)\n",
    "                    # find out the upper bound of index\n",
    "                    upper = int(frequency*(m+1))\n",
    "                    \n",
    "                    # Assign the corresponding level label to the corresponding instance \n",
    "                    copy_feature[feature.sort_values()[lower:upper].index] = ('category'+ str(levels-m))\n",
    "            copy_data[i] = copy_feature\n",
    "    return copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Equal Width:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>category1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>category1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category2</td>\n",
       "      <td>Private</td>\n",
       "      <td>category1</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                 1          2          3   4                   5   \\\n",
       "0  category2         State-gov  category1  Bachelors  13       Never-married   \n",
       "1  category3  Self-emp-not-inc  category1  Bachelors  13  Married-civ-spouse   \n",
       "2  category2           Private  category1    HS-grad   9            Divorced   \n",
       "\n",
       "                  6              7      8     9          10         11  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male  category1  category1   \n",
       "1    Exec-managerial        Husband  White  Male  category1  category1   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male  category1  category1   \n",
       "\n",
       "          12             13     14  \n",
       "0  category2  United-States  <=50K  \n",
       "1  category1  United-States  <=50K  \n",
       "2  category2  United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Equal Frequency:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category3</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>category5</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category1</td>\n",
       "      <td>category5</td>\n",
       "      <td>category4</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category2</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>category5</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category2</td>\n",
       "      <td>category2</td>\n",
       "      <td>category5</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category3</td>\n",
       "      <td>Private</td>\n",
       "      <td>category2</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>category2</td>\n",
       "      <td>category2</td>\n",
       "      <td>category2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                 1          2          3   4                   5   \\\n",
       "0  category3         State-gov  category5  Bachelors  13       Never-married   \n",
       "1  category2  Self-emp-not-inc  category5  Bachelors  13  Married-civ-spouse   \n",
       "2  category3           Private  category2    HS-grad   9            Divorced   \n",
       "\n",
       "                  6              7      8     9          10         11  \\\n",
       "0       Adm-clerical  Not-in-family  White  Male  category1  category5   \n",
       "1    Exec-managerial        Husband  White  Male  category2  category2   \n",
       "2  Handlers-cleaners  Not-in-family  White  Male  category2  category2   \n",
       "\n",
       "          12             13     14  \n",
       "0  category4  United-States  <=50K  \n",
       "1  category5  United-States  <=50K  \n",
       "2  category2  United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width_data_level_5 = discretise(train_data,levels=5,by='width')\n",
    "freq_data_level_5 = discretise(train_data,levels=5,by='freq')\n",
    "\n",
    "width_data_level_10 = discretise(train_data,levels=10,by='width')\n",
    "freq_data_level_10 = discretise(train_data,levels=10,by='freq')\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Width:\")\n",
    "display(width_data_level_5.head(3))\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Frequency:\")\n",
    "display(freq_data_level_5.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use width discretise with 5 levels\n",
      "{'correct_rate': 0.8130760559644586}\n",
      "Use width discretise with 10 levels\n",
      "{'correct_rate': 0.8181818181818182}\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "print(\"Use width discretise with 5 levels\")\n",
    "print(calc_outcome(width_data_level_5))\n",
    "print(\"Use width discretise with 10 levels\")\n",
    "print(calc_outcome(width_data_level_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use frequency discretise with 5 levels\n",
      "{'correct_rate': 0.810257940454877}\n",
      "Use frequency discretise with 10 levels\n",
      "{'correct_rate': 0.8137059876666004}\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "print(\"Use frequency discretise with 5 levels\")\n",
    "print(calc_outcome(freq_data_level_5))\n",
    "print(\"Use frequency discretise with 10 levels\")\n",
    "print(calc_outcome(freq_data_level_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the na¨ıve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the na¨ıve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_r_evaluate(data,label_index):\n",
    "    temp_data = data.copy()\n",
    "    # Find out the most class label\n",
    "    zero_r_result = temp_data[label_index].value_counts().idxmax()\n",
    "    #Convert to List data type to avoid error\n",
    "    series_of_class = temp_data[label_index]\n",
    "    list_of_class = series_of_class.values.tolist()\n",
    "    \n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "\n",
    "    for i in range(len(list_of_class)):\n",
    "        #Calculate how many labels of the most type\n",
    "        if zero_r_result == list_of_class[i]:\n",
    "            correct += 1\n",
    "    correct_rate = correct / total\n",
    "    \n",
    "    return correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some 0R baseline model for varius dataset:\n",
      "======================================================\n",
      "0R baseline model performance for brest dataset:\n",
      "0.6500732064421669\n",
      "======================================================\n",
      "0R baseline model performance for mushroom dataset:\n",
      "0.6180014174344437\n",
      "======================================================\n",
      "0R baseline model performance for lymphography dataset:\n",
      "0.5472972972972973\n",
      "======================================================\n",
      "0R baseline model performance for wdbc dataset:\n",
      "0.6274165202108963\n",
      "======================================================\n",
      "0R baseline model performance for wine dataset:\n",
      "0.398876404494382\n",
      "======================================================\n",
      "0R baseline model performance for car dataset:\n",
      "0.6998264893001735\n",
      "======================================================\n",
      "0R baseline model performance for nursery dataset:\n",
      "0.3333333333333333\n",
      "======================================================\n",
      "0R baseline model performance for somerville dataset:\n",
      "0.5384615384615384\n",
      "======================================================\n",
      "0R baseline model performance for adult dataset:\n",
      "0.7510775147536636\n",
      "======================================================\n",
      "0R baseline model performance for bank dataset:\n",
      "0.8830151954170445\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Some 0R baseline model for varius dataset:\")\n",
    "\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for brest dataset:\")\n",
    "brest_0R_data = preprocess(breast_cancer_wisconsin,\"?\",0) \n",
    "print(zero_r_evaluate(brest_0R_data,10))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for mushroom dataset:\")\n",
    "mushroom_0R_data = preprocess(mushroom,\"?\") \n",
    "print(zero_r_evaluate(mushroom_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for lymphography dataset:\")\n",
    "lymphography_0R_data = preprocess(lymphography,None) \n",
    "print(zero_r_evaluate(lymphography_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for wdbc dataset:\")\n",
    "wdbc_0R_data = preprocess(wdbc,\"?\",0) \n",
    "print(zero_r_evaluate(wdbc_0R_data,1))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for wine dataset:\")\n",
    "wine_0R_data = preprocess(wine,None) \n",
    "print(zero_r_evaluate(wine_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for car dataset:\")\n",
    "car_0R_data = preprocess(car,None) \n",
    "print(zero_r_evaluate(car_0R_data,6))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for nursery dataset:\")\n",
    "nursery_0R_data = preprocess(nursery,None) \n",
    "print(zero_r_evaluate(nursery_0R_data,8))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for somerville dataset:\")\n",
    "somerville_0R_data = preprocess(somerville,None) \n",
    "print(zero_r_evaluate(somerville_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for adult dataset:\")\n",
    "adult_0R_data = preprocess(adult,'?') \n",
    "print(zero_r_evaluate(adult_0R_data,14))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for bank dataset:\")\n",
    "bank_0R_data = preprocess(bank,None) \n",
    "print(zero_r_evaluate(bank_0R_data,14))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Since it’s difficult to model the probabilities of ordinal data, ordinal attributes are often treated as either nominal variables or numeric variables. Compare these strategies on the ordinal datasets provided. Deterimine which approach gives higher classification accuracy and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when datasets_types is NOMINAL: \n",
      "{'correct_rate': 0.8739155581260845}\n",
      "when datasets_types is NUMERIC: \n",
      "{'correct_rate': 0.6350491613649508}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "learn from :https://stackoverflow.com/questions/21818886/changing-ordinal-character-data-to-numeric-data-with-pandas\n",
    "use dicttionary to convert ordinal value to numeric value\n",
    "'''\n",
    "car_origin = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "car = car_origin.copy()\n",
    "buying_conv_dict= {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[0]=car[0].apply(buying_conv_dict.get)\n",
    "maint_conv_dict = {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[1]=car[1].apply(maint_conv_dict.get)\n",
    "doors_conv_dict = {'2':1, '3':2, '4':3, '5more': 4}\n",
    "car[2]=car[2].apply(doors_conv_dict.get)\n",
    "persons_conv_dict = {'2':0, '4':1, 'more':2}\n",
    "car[3]=car[3].apply(persons_conv_dict.get)\n",
    "lug_boot_conv_dict = {'small':0,'med':1, 'big':2}\n",
    "car[4]=car[4].apply(lug_boot_conv_dict.get)\n",
    "safety_conv_dict = {'low':0 , 'med':1, 'high':2}\n",
    "car[5]=car[5].apply(safety_conv_dict.get)\n",
    "class_conv_dict = {'unacc':0 , 'acc':1, 'good':2, 'vgood':3}\n",
    "car[6]=car[6].apply(class_conv_dict.get)\n",
    "\n",
    "#use nominal to calculate\n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 6\n",
    "label = car_origin.iloc[:,class_column]\n",
    "train_set = car_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "print(\"when datasets_types is NOMINAL: \")\n",
    "print(calc_outcome(car_origin))\n",
    "\n",
    "#use numercial to calculate \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 6\n",
    "print(\"when datasets_types is NUMERIC: \")\n",
    "print(calc_outcome(car))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>inconv</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>very_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1         2  3           4           5              6  \\\n",
       "0  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "1  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "2  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "3  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "4  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "5  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "6  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "7  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "8  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "9  usual  proper  complete  1  convenient      inconv        nonprob   \n",
       "\n",
       "             7           8  \n",
       "0  recommended   recommend  \n",
       "1     priority    priority  \n",
       "2    not_recom   not_recom  \n",
       "3  recommended   recommend  \n",
       "4     priority    priority  \n",
       "5    not_recom   not_recom  \n",
       "6  recommended    priority  \n",
       "7     priority    priority  \n",
       "8    not_recom   not_recom  \n",
       "9  recommended  very_recom  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nursery.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when datasets_types is NOMINAL: \n",
      "{'correct_rate': 0.9030864197530865}\n",
      "when datasets_types is NUMERIC: \n",
      "{'correct_rate': 0.6327932098765432}\n"
     ]
    }
   ],
   "source": [
    "nursery_origin = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "\n",
    "nursery_numeric = nursery_origin.copy()\n",
    "\n",
    "parents_dict = {'usual':0, 'pretentious':1, 'great_pret':2}\n",
    "nursery_numeric[0]=nursery_numeric[0].apply(parents_dict.get)\n",
    "has_nurs_dict ={'proper':0, 'less_proper':1, 'improper':2, 'critical':3, 'very_crit':4}\n",
    "nursery_numeric[1]=nursery_numeric[1].apply(has_nurs_dict.get)\n",
    "form_dict = {'complete':0, 'completed':1, 'incomplete':2, 'foster':3}\n",
    "nursery_numeric[2]=nursery_numeric[2].apply(form_dict.get)\n",
    "children_dict ={'1':0, '2':1, '3':2, 'more':3}\n",
    "nursery_numeric[3]=nursery_numeric[3].apply(children_dict.get)\n",
    "housing_dict = {'convenient':0, 'less_conv':1, 'critical':2}\n",
    "nursery_numeric[4]=nursery_numeric[4].apply(housing_dict.get)\n",
    "finance_dict = {'convenient':0, 'inconv':1}\n",
    "nursery_numeric[5]=nursery_numeric[5].apply(finance_dict.get)\n",
    "social_dict = {'nonprob':0, 'slightly_prob':1, 'problematic':2}\n",
    "nursery_numeric[6]=nursery_numeric[6].apply(social_dict.get)\n",
    "health_dict = {'recommended':0, 'priority':1, 'not_recom':2}\n",
    "nursery_numeric[7]=nursery_numeric[7].apply(health_dict.get)\n",
    "class_dict = {'not_recom':0, 'recommend':1, 'very_recom':2, 'priority':3, 'spec_prior':4}\n",
    "nursery_numeric[8]=nursery_numeric[8].apply(class_dict.get)\n",
    "\n",
    "#nominal \n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 8\n",
    "label = nursery_origin.iloc[:,class_column]\n",
    "train_set = nursery_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "print(\"when datasets_types is NOMINAL: \")\n",
    "print(calc_outcome(nursery_origin))\n",
    "\n",
    "#numercial \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 8\n",
    "print(\"when datasets_types is NUMERIC: \")\n",
    "print(calc_outcome(nursery_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hold_out\n",
    "def separate_data(data):\n",
    "    X_train = data.sample(frac = 0.8, random_state = 123)\n",
    "    X_test  = data.drop(index = X_train.index)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different datasets to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% brest dataset(after hold out)\n",
      "{'correct_rate': 0.978021978021978}\n",
      "Accuracy for 20% brest test dataset(after hold out)\n",
      "{'correct_rate': 0.9708029197080292}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = 0\n",
    "class_column = 10\n",
    "missing_values = '?'\n",
    "train_data = preprocess(breast_cancer_wisconsin, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "brest_train,brest_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% brest dataset(after hold out)\")\n",
    "print(calc_outcome(brest_train))\n",
    "print(\"Accuracy for 20% brest test dataset(after hold out)\")\n",
    "print(calc_outcome(brest_train, test_data = brest_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% mushroom dataset (after hold out):\n",
      "{'correct_rate': 0.9920265780730897}\n",
      "Accuracy for 20% mushroom test dataset(after hold out)\n",
      "{'correct_rate': 0.9911426040744021}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = '?'\n",
    "train_data = preprocess(mushroom, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "mushroom_train,mushroom_test = separate_data(train_data,)\n",
    "print(\"Accuracy for 80% mushroom dataset (after hold out):\")\n",
    "print(calc_outcome(mushroom_train))\n",
    "print(\"Accuracy for 20% mushroom test dataset(after hold out)\")\n",
    "print(calc_outcome(mushroom_train, test_data = mushroom_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% lymphography dataset (after hold out):\n",
      "{'correct_rate': 0.8898305084745762}\n",
      "Accuracy for 20% lymphography test dataset (after hold out):\n",
      "{'correct_rate': 0.8333333333333334}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(lymphography, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "lymphography_train,lymphography_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% lymphography dataset (after hold out):\")\n",
    "print(calc_outcome(lymphography_train))\n",
    "print(\"Accuracy for 20% lymphography test dataset (after hold out):\")\n",
    "print(calc_outcome(lymphography_train, test_data = lymphography_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% wdbc dataset (after hold out):\n",
      "{'correct_rate': 0.9384615384615385}\n",
      "Accuracy for 20% wdbc test dataset (after hold out):\n",
      "{'correct_rate': 0.9210526315789473}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NUMERIC\"\n",
    "id_column = 0\n",
    "class_column = 1\n",
    "missing_values = None\n",
    "train_data = preprocess(wdbc, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "wdbc_train,wdbc_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% wdbc dataset (after hold out):\")\n",
    "print(calc_outcome(wdbc_train))\n",
    "print(\"Accuracy for 20% wdbc test dataset (after hold out):\")\n",
    "print(calc_outcome(wdbc_train, test_data = wdbc_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% wine dataset (after hold out):\n",
      "{'correct_rate': 0.9929577464788732}\n",
      "Accuracy for 20% wine test (after hold out):\n",
      "{'correct_rate': 0.9722222222222222}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NUMERIC\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(wine, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "wine_train,wine_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% wine dataset (after hold out):\")\n",
    "print(calc_outcome(wine_train))\n",
    "print(\"Accuracy for 20% wine test (after hold out):\")\n",
    "print(calc_outcome(wine_train, test_data = wine_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% car dataset(after hold out)\n",
      "{'correct_rate': 0.8705712219812003}\n",
      "Accuracy for 20% car test dataset(after hold out)\n",
      "{'correct_rate': 0.8583815028901735}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 6\n",
    "missing_values = None\n",
    "train_data = preprocess(car, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "car_train,car_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% car dataset(after hold out)\")\n",
    "print(calc_outcome(car_train))\n",
    "print(\"Accuracy for 20% car test dataset(after hold out)\")\n",
    "print(calc_outcome(car_train, test_data = car_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% nursery dataset(after hold out)\n",
      "{'correct_rate': 0.9037422839506173}\n",
      "Accuracy for 20% nursery test dataset(after hold out)\n",
      "{'correct_rate': 0.8985339506172839}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 8\n",
    "missing_values = None\n",
    "train_data = preprocess(nursery, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "nursery_train,nursery_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% nursery dataset(after hold out)\")\n",
    "print(calc_outcome(nursery_train))\n",
    "print(\"Accuracy for 20% nursery test dataset(after hold out)\")\n",
    "print(calc_outcome(nursery_train, test_data = nursery_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% somerville dataset(after hold out)\n",
      "{'correct_rate': 0.7017543859649122}\n",
      "Accuracy for 20% somerville test dataset(after hold out)\n",
      "{'correct_rate': 0.5172413793103449}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(somerville, missing_values,id_column)\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "somerville_train,somerville_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% somerville dataset(after hold out)\")\n",
    "print(calc_outcome(somerville_train))\n",
    "print(\"Accuracy for 20% somerville test dataset(after hold out)\")\n",
    "print(calc_outcome(somerville_train, test_data = somerville_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% adult dataset(after hold out)\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"MIX\"\n",
    "id_column = None\n",
    "class_column = 14\n",
    "missing_values = '?'\n",
    "train_data = preprocess(adult, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "adult_train,adult_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% adult dataset(after hold out)\")\n",
    "print(calc_outcome(adult_train))\n",
    "print(\"Accuracy for 20% adult test dataset(after hold out)\")\n",
    "print(calc_outcome(adult_train, test_data = adult_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_types = \"MIX\"\n",
    "id_column = None\n",
    "class_column = 14\n",
    "missing_values = None\n",
    "train_data = preprocess(bank, missing_values,id_column)\n",
    "feature_types = [2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0]\n",
    "# Seperate the label and data\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "bank_train,bank_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% bank dataset(after hold out)\")\n",
    "print(calc_outcome(bank_train))\n",
    "print(\"Accuracy for 20% bank test dataset(after hold out)\")\n",
    "print(calc_outcome(bank_train, test_data = bank_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
