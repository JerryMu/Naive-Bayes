{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `Pengyu Mu, Ziyuan Xiao`\n",
    "\n",
    "**Student ID(s):**     `890756, 940448`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Read all datasets \n",
    "adult = pd.read_csv(\"datasets/adult.data\", header = None)\n",
    "bank = pd.read_csv(\"datasets/bank.data\", header = None)\n",
    "breast_cancer_wisconsin = pd.read_csv(\"datasets/breast-cancer-wisconsin.data\", header = None)\n",
    "car = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "lymphography = pd.read_csv(\"datasets/lymphography.data\", header = None)\n",
    "mushroom = pd.read_csv(\"datasets/mushroom.data\", header = None)\n",
    "nursery = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "somerville = pd.read_csv(\"datasets/somerville.data\", header = None)\n",
    "university = pd.read_csv(\"datasets/university.data\", header = None)\n",
    "wdbc = pd.read_csv(\"datasets/wdbc.data\", header = None)\n",
    "wine = pd.read_csv(\"datasets/wine.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function that delete all missing values\n",
    "def delete_missing_value(raw_dataset, missing_values):\n",
    "    rows = set(raw_dataset[raw_dataset.values == missing_values].index)\n",
    "    data = raw_dataset.drop(index = rows)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    This function should prepare the data by reading it from a file and\n",
    "#    converting it into a useful format for later training and testing\n",
    "\n",
    "def preprocess(df, missing_values, id_column = None):\n",
    "    train = delete_missing_value(df, missing_values)\n",
    "    if id_column != None:\n",
    "        train = train.drop(columns = [id_column])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape =====> (569, 31)\n",
      "======================================================\n",
      "EPSILON ========> 0.0008787346221441124\n",
      "======================================================\n",
      "Some Data Examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  1      2      3      4       5        6        7       8        9       10  \\\n",
       "0  M  17.99  10.38  122.8  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  M  20.57  17.77  132.9  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  M  19.69  21.25  130.0  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "\n",
       "   ...     22     23     24      25      26      27      28      29      30  \\\n",
       "0  ...  25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "1  ...  24.99  23.41  158.8  1956.0  0.1238  0.1866  0.2416  0.1860  0.2750   \n",
       "2  ...  23.57  25.53  152.5  1709.0  0.1444  0.4245  0.4504  0.2430  0.3613   \n",
       "\n",
       "        31  \n",
       "0  0.11890  \n",
       "1  0.08902  \n",
       "2  0.08758  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Data Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      object\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10    float64\n",
       "11    float64\n",
       "12    float64\n",
       "13    float64\n",
       "14    float64\n",
       "15    float64\n",
       "16    float64\n",
       "17    float64\n",
       "18    float64\n",
       "19    float64\n",
       "20    float64\n",
       "21    float64\n",
       "22    float64\n",
       "23    float64\n",
       "24    float64\n",
       "25    float64\n",
       "26    float64\n",
       "27    float64\n",
       "28    float64\n",
       "29    float64\n",
       "30    float64\n",
       "31    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global Variable\n",
    "\n",
    "# index column that need to be remove\n",
    "# Assign None to id_column means no id column\n",
    "id_column = 0\n",
    "\n",
    "#  Enter dataset here\n",
    "missing_values = None\n",
    "train_data = preprocess(wdbc, missing_values,id_column)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "\n",
    "# Enter type of datasets\n",
    "\n",
    "datasets_types = \"NUMERIC\"\n",
    "\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "# Only works when dataset_types equals MIX\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "class_column = 1\n",
    "\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# Seperate the label and data\n",
    "label = train_data.iloc[:,class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "# Show some useful information about the data\n",
    "print(\"Data Shape =====>\", train_data.shape)\n",
    "print(\"======================================================\")\n",
    "print(\"EPSILON ========>\", EPSILON)\n",
    "print(\"======================================================\")\n",
    "print(\"Some Data Examples:\")\n",
    "display(train_data.head(3))\n",
    "print(\"======================================================\")\n",
    "print(\"Data Type:\")\n",
    "display(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate prior\n",
    "def find_nominal_prob(class_column):\n",
    "    prior = {}\n",
    "    total_number = len(class_column)\n",
    "    classes = class_column.value_counts()\n",
    "    for key in classes.keys():\n",
    "        prior[key] = math.log2(classes[key]/total_number)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': -0.6725045782774821, 'M': -1.424364387743383}\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior\n",
    "print(find_nominal_prob(train_data[class_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nominal_llh(attributes, llh_dict, data, feature_row):\n",
    "    all_feature = data[feature_row].value_counts()\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature_row:{}}\n",
    "        subset = data[data[class_column] == attribute][feature_row]\n",
    "        feature_dict[feature_row] = find_nominal_prob(subset)\n",
    "        for check_feature in all_feature.keys():\n",
    "            if check_feature not in feature_dict[feature_row].keys():\n",
    "                feature_dict[feature_row][check_feature] = np.log2(EPSILON)\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "            \n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_numerical_llh(attributes, llh_dict, data, feature):\n",
    "#  Save mean and Std as llh\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature:{}}\n",
    "        subset = subset = data[data[class_column] == attribute][feature]\n",
    "        mean = np.mean(subset)\n",
    "        std = np.std(subset)\n",
    "        feature_dict[feature][\"mean\"] = mean\n",
    "        feature_dict[feature][\"std\"] = std\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function should calculat prior probabilities and likelihoods from the training data\n",
    "#  and using them to build a naive Bayes model\n",
    "\n",
    "def train(data):\n",
    "    prior = find_nominal_prob(data[class_column])\n",
    "    llh_dict = dict.fromkeys(prior)\n",
    "    for i in feature_columns:\n",
    "        if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "            find_numerical_llh(prior, llh_dict, data, i)\n",
    "        else:\n",
    "            find_nominal_llh(prior, llh_dict, data, i)\n",
    "            \n",
    "    return prior, llh_dict\n",
    "\n",
    "prior, llh_dict = train(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "def predict(instance, prior, llh_dict):\n",
    "    all_prob = {}\n",
    "    for attribute in prior.keys():\n",
    "        all_prob[attribute] = prior[attribute]\n",
    "        for i in feature_columns:\n",
    "            prob = 0\n",
    "            if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "                mean = max(llh_dict[attribute][i][\"mean\"], 1 * 10 ** -8)\n",
    "                std = max(llh_dict[attribute][i][\"std\"], 1 * 10 ** -8)\n",
    "                prob = stats.norm.pdf(x=instance[i], loc=mean, scale=std)\n",
    "                if prob > 0.0:\n",
    "                    prob = np.log2(prob)\n",
    "                else:\n",
    "                    prob = np.log2(1 * 10 ** -8)\n",
    "            else:\n",
    "                prob = llh_dict[attribute][i][instance[i]]\n",
    "            all_prob[attribute] += prob\n",
    "    max_prob = -10000\n",
    "    max_key = \"\"\n",
    "    \n",
    "    for prob in all_prob.keys():\n",
    "        if(all_prob[prob] > max_prob):\n",
    "            max_prob = all_prob[prob]\n",
    "            max_key = prob\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of the prediction working\n",
    "predict(train_data.iloc[0], prior, llh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Overall Accuracy is: \n",
      "correct 535 569\n",
      "{'correct_rate': 0.9402460456942003}\n"
     ]
    }
   ],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels\n",
    "\n",
    "def evaluate(data, prior, llh_dict, interesting_class = None):\n",
    "    predict_list = []\n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "    result = {}\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        actual_class = row[class_column]\n",
    "        predict_class = predict(row, prior, llh_dict)\n",
    "        if (actual_class == predict_class):\n",
    "            correct += 1\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    TP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    TN += 1\n",
    "        else:\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    FP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    FN += 1\n",
    "                    \n",
    "    correct_rate = correct/total\n",
    "    result[\"correct_rate\"] = correct_rate\n",
    "    \n",
    "    if (interesting_class):\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        result[\"precision\"] = precision\n",
    "        result[\"recall\"] = recall\n",
    "    print(\"correct\",correct,total)\n",
    "    return result\n",
    "# %time\n",
    "print(\"======================================================\")\n",
    "print(\"Overall Accuracy is: \")\n",
    "print(evaluate(train_data, prior, llh_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper fuction for later use\n",
    "# This function could quickly calculate the result\n",
    "def calc_outcome(data):\n",
    "    data_train,data_llh_dict = train(data)\n",
    "    data_eval = evaluate(data,data_train,data_llh_dict)\n",
    "    return data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 535 569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct_rate': 0.9402460456942003}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of using calc_outcome\n",
    "calc_outcome(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the na¨ıve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian na¨ıve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use adult dataset for this question\n",
    "\n",
    "# index column that need to be remove\n",
    "# Assign None to id_column means no id column\n",
    "id_column = None\n",
    "\n",
    "#  Enter dataset here\n",
    "missing_values = None\n",
    "train_data = preprocess(bank, missing_values,id_column)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "\n",
    "# Enter type of datasets\n",
    "datasets_types = \"MIX\"\n",
    "\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "# Only works when dataset_types is MIX\n",
    "feature_types = [2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0]\n",
    "class_column = 14\n",
    "\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# 分开label和数据\n",
    "label = train_data[class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "\n",
    "def discretise(data,levels,by):\n",
    "    #Given a data set and its corresponding data type,\n",
    "    #All its features must be discretized into discrete features，\n",
    "    #Takes an integer, then determine the total number of discrete feature levels\n",
    "\n",
    "    copy_data = data.copy()\n",
    "    for i in feature_columns:\n",
    "        # Find out all the Numeric Data, and then form a new DataFrame\n",
    "        # Note: 2 means numeric data type\n",
    "        if datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2): \n",
    "            feature = data[i]\n",
    "            copy_feature = feature.copy()\n",
    "            \n",
    "            # Equal Width\n",
    "            if by =='width':\n",
    "                # After finding maximum and minimux,\n",
    "                # calculate the width of each level\n",
    "                maximum = np.max(feature)\n",
    "                minimum = np.min(feature)\n",
    "                width = (maximum-minimum)/levels\n",
    "                # Assign the corresponding level label to the corresponding instance \n",
    "                for j in range(levels):\n",
    "                    copy_feature[feature<=(maximum-width*j)] = ('category'+str(levels-j))\n",
    "           \n",
    "            # Equal Frequency\n",
    "            else:\n",
    "                # Calculate the frequency of each level\n",
    "                frequency = feature.shape[0]/levels \n",
    "                for m in range(levels):\n",
    "                    # find out the lower bound of index\n",
    "                    lower = int(frequency*m)\n",
    "                    # find out the upper bound of index\n",
    "                    upper = int(frequency*(m+1))\n",
    "                    \n",
    "                    # Assign the corresponding level label to the corresponding instance \n",
    "                    copy_feature[feature.sort_values()[lower:upper].index] = ('category'+ str(levels-m))\n",
    "            copy_data[i] = copy_feature\n",
    "    return copy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Equal Width:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category3</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>category1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category2</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>category1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category1</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>category1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>category1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0             1        2          3   4          5    6    7   \\\n",
       "0  category3    management  married   tertiary  no  category1  yes   no   \n",
       "1  category2    technician   single  secondary  no  category1  yes   no   \n",
       "2  category1  entrepreneur  married  secondary  no  category1  yes  yes   \n",
       "\n",
       "        8          9          10         11         12       13  14  \n",
       "0  unknown  category1  category1  category1  category1  unknown  no  \n",
       "1  unknown  category1  category1  category1  category1  unknown  no  \n",
       "2  unknown  category1  category1  category1  category1  unknown  no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Equal Frequency:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category1</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>category1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category2</td>\n",
       "      <td>category5</td>\n",
       "      <td>category5</td>\n",
       "      <td>category5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category2</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>category4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category3</td>\n",
       "      <td>category4</td>\n",
       "      <td>category3</td>\n",
       "      <td>category3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category4</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>category5</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>category5</td>\n",
       "      <td>category4</td>\n",
       "      <td>category3</td>\n",
       "      <td>category3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0             1        2          3   4          5    6    7   \\\n",
       "0  category1    management  married   tertiary  no  category1  yes   no   \n",
       "1  category2    technician   single  secondary  no  category4  yes   no   \n",
       "2  category4  entrepreneur  married  secondary  no  category5  yes  yes   \n",
       "\n",
       "        8          9          10         11         12       13  14  \n",
       "0  unknown  category2  category5  category5  category5  unknown  no  \n",
       "1  unknown  category3  category4  category3  category3  unknown  no  \n",
       "2  unknown  category5  category4  category3  category3  unknown  no  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width_data = discretise(train_data,levels=5,by='width')\n",
    "freq_data = discretise(train_data,levels=5,by='freq')\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Width:\")\n",
    "display(width_data.head(3))\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Frequency:\")\n",
    "display(freq_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 40177 45211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct_rate': 0.8886554157174139}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "calc_outcome(width_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 39398 45211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct_rate': 0.87142509566256}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "calc_outcome(freq_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the na¨ıve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the na¨ıve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_r_evaluate(data,label_index):\n",
    "    temp_data = data.copy()\n",
    "    # Find out the most class label\n",
    "    zero_r_result = temp_data[label_index].value_counts().idxmax()\n",
    "    #Convert to List data type to avoid error\n",
    "    series_of_class = temp_data[label_index]\n",
    "    list_of_class = series_of_class.values.tolist()\n",
    "    \n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "\n",
    "    for i in range(len(list_of_class)):\n",
    "        #Calculate how many labels of the most type\n",
    "        if zero_r_result == list_of_class[i]:\n",
    "            correct += 1\n",
    "    correct_rate = correct / total\n",
    "    \n",
    "    return correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some 0R baseline model for varius dataset:\n",
      "======================================================\n",
      "0R baseline model performance for brest dataset:\n",
      "0.6500732064421669\n",
      "======================================================\n",
      "0R baseline model performance for mushroom dataset:\n",
      "0.6180014174344437\n",
      "======================================================\n",
      "0R baseline model performance for lymphography dataset:\n",
      "0.5472972972972973\n",
      "======================================================\n",
      "0R baseline model performance for wdbc dataset:\n",
      "0.6274165202108963\n",
      "======================================================\n",
      "0R baseline model performance for wine dataset:\n",
      "0.398876404494382\n",
      "======================================================\n",
      "0R baseline model performance for car dataset:\n",
      "0.6998264893001735\n",
      "======================================================\n",
      "0R baseline model performance for nursery dataset:\n",
      "0.3333333333333333\n",
      "======================================================\n",
      "0R baseline model performance for somerville dataset:\n",
      "0.5384615384615384\n",
      "======================================================\n",
      "0R baseline model performance for adult dataset:\n",
      "0.7510775147536636\n",
      "======================================================\n",
      "0R baseline model performance for bank dataset:\n",
      "0.8830151954170445\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Some 0R baseline model for varius dataset:\")\n",
    "\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for brest dataset:\")\n",
    "brest_0R_data = preprocess(breast_cancer_wisconsin,\"?\",0) \n",
    "print(zero_r_evaluate(brest_0R_data,10))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for mushroom dataset:\")\n",
    "mushroom_0R_data = preprocess(mushroom,\"?\") \n",
    "print(zero_r_evaluate(mushroom_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for lymphography dataset:\")\n",
    "lymphography_0R_data = preprocess(lymphography,None) \n",
    "print(zero_r_evaluate(lymphography_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for wdbc dataset:\")\n",
    "wdbc_0R_data = preprocess(wdbc,\"?\",0) \n",
    "print(zero_r_evaluate(wdbc_0R_data,1))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for wine dataset:\")\n",
    "wine_0R_data = preprocess(wine,None) \n",
    "print(zero_r_evaluate(wine_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for car dataset:\")\n",
    "car_0R_data = preprocess(car,None) \n",
    "print(zero_r_evaluate(car_0R_data,6))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for nursery dataset:\")\n",
    "nursery_0R_data = preprocess(nursery,None) \n",
    "print(zero_r_evaluate(nursery_0R_data,8))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for somerville dataset:\")\n",
    "somerville_0R_data = preprocess(somerville,None) \n",
    "print(zero_r_evaluate(somerville_0R_data,0))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for adult dataset:\")\n",
    "adult_0R_data = preprocess(adult,'?') \n",
    "print(zero_r_evaluate(adult_0R_data,14))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for bank dataset:\")\n",
    "bank_0R_data = preprocess(bank,None) \n",
    "print(zero_r_evaluate(bank_0R_data,14))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Since it’s difficult to model the probabilities of ordinal data, ordinal attributes are often treated as either nominal variables or numeric variables. Compare these strategies on the ordinal datasets provided. Deterimine which approach gives higher classification accuracy and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc\n",
       "5  vhigh  vhigh  2  2    med  high  unacc\n",
       "6  vhigh  vhigh  2  2    big   low  unacc\n",
       "7  vhigh  vhigh  2  2    big   med  unacc\n",
       "8  vhigh  vhigh  2  2    big  high  unacc\n",
       "9  vhigh  vhigh  2  4  small   low  unacc"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use car dataset for this question\n",
    "car.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when datasets_types is NOMINAL: \n",
      "correct 1511 1729\n",
      "{'correct_rate': 0.8739155581260845}\n",
      "when datasets_types is NUMERIC: \n",
      "correct 1098 1729\n",
      "{'correct_rate': 0.6350491613649508}\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/21818886/changing-ordinal-character-data-to-numeric-data-with-pandas\n",
    "car_origin = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "car = car_origin.copy()\n",
    "buying_conv_dict= {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[0]=car[0].apply(buying_conv_dict.get)\n",
    "maint_conv_dict = {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[1]=car[1].apply(maint_conv_dict.get)\n",
    "doors_conv_dict = {'2':1, '3':2, '4':3, '5more': 4}\n",
    "car[2]=car[2].apply(doors_conv_dict.get)\n",
    "persons_conv_dict = {'2':0, '4':1, 'more':2}\n",
    "car[3]=car[3].apply(persons_conv_dict.get)\n",
    "lug_boot_conv_dict = {'small':0,'med':1, 'big':2}\n",
    "car[4]=car[4].apply(lug_boot_conv_dict.get)\n",
    "safety_conv_dict = {'low':0 , 'med':1, 'high':2}\n",
    "car[5]=car[5].apply(safety_conv_dict.get)\n",
    "class_conv_dict = {'unacc':0 , 'acc':1, 'good':2, 'vgood':3}\n",
    "car[6]=car[6].apply(class_conv_dict.get)\n",
    "\n",
    "#nominal \n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 6\n",
    "label = car_origin.iloc[:,class_column]\n",
    "train_set = car_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "prior, llh_dict = train(car_origin)\n",
    "print(\"when datasets_types is NOMINAL: \")\n",
    "print(evaluate(car_origin, prior, llh_dict))\n",
    "\n",
    "#numercial \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 6\n",
    "prior, llh_dict = train(car)\n",
    "print(\"when datasets_types is NUMERIC: \")\n",
    "\n",
    "print(evaluate(car, prior, llh_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>inconv</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>very_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1         2  3           4           5              6  \\\n",
       "0  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "1  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "2  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "3  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "4  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "5  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "6  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "7  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "8  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "9  usual  proper  complete  1  convenient      inconv        nonprob   \n",
       "\n",
       "             7           8  \n",
       "0  recommended   recommend  \n",
       "1     priority    priority  \n",
       "2    not_recom   not_recom  \n",
       "3  recommended   recommend  \n",
       "4     priority    priority  \n",
       "5    not_recom   not_recom  \n",
       "6  recommended    priority  \n",
       "7     priority    priority  \n",
       "8    not_recom   not_recom  \n",
       "9  recommended  very_recom  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nursery.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when datasets_types is NOMINAL: \n",
      "correct 11704 12960\n",
      "{'correct_rate': 0.9030864197530865}\n",
      "when datasets_types is NUMERIC: \n"
     ]
    }
   ],
   "source": [
    "nursery_origin = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "\n",
    "nursery_numeric = nursery_origin.copy()\n",
    "\n",
    "parents_dict = {'usual':0, 'pretentious':1, 'great_pret':2}\n",
    "nursery_numeric[0]=nursery_numeric[0].apply(parents_dict.get)\n",
    "has_nurs_dict ={'proper':0, 'less_proper':1, 'improper':2, 'critical':3, 'very_crit':4}\n",
    "nursery_numeric[1]=nursery_numeric[1].apply(has_nurs_dict.get)\n",
    "form_dict = {'complete':0, 'completed':1, 'incomplete':2, 'foster':3}\n",
    "nursery_numeric[2]=nursery_numeric[2].apply(form_dict.get)\n",
    "children_dict ={'1':0, '2':1, '3':2, 'more':3}\n",
    "nursery_numeric[3]=nursery_numeric[3].apply(children_dict.get)\n",
    "housing_dict = {'convenient':0, 'less_conv':1, 'critical':2}\n",
    "nursery_numeric[4]=nursery_numeric[4].apply(housing_dict.get)\n",
    "finance_dict = {'convenient':0, 'inconv':1}\n",
    "nursery_numeric[5]=nursery_numeric[5].apply(finance_dict.get)\n",
    "social_dict = {'nonprob':0, 'slightly_prob':1, 'problematic':2}\n",
    "nursery_numeric[6]=nursery_numeric[6].apply(social_dict.get)\n",
    "health_dict = {'recommended':0, 'priority':1, 'not_recom':2}\n",
    "nursery_numeric[7]=nursery_numeric[7].apply(health_dict.get)\n",
    "class_dict = {'not_recom':0, 'recommend':1, 'very_recom':2, 'priority':3, 'spec_prior':4}\n",
    "nursery_numeric[8]=nursery_numeric[8].apply(class_dict.get)\n",
    "\n",
    "#nominal \n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 8\n",
    "label = nursery_origin.iloc[:,class_column]\n",
    "train_set = nursery_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "prior, llh_dict = train(nursery_origin)\n",
    "print(\"when datasets_types is NOMINAL: \")\n",
    "\n",
    "print(evaluate(nursery_origin, prior, llh_dict))\n",
    "\n",
    "#numercial \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 8\n",
    "prior, llh_dict = train(nursery_numeric)\n",
    "print(\"when datasets_types is NUMERIC: \")\n",
    "\n",
    "print(evaluate(nursery_numeric, prior, llh_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variable\n",
    "\n",
    "# Enter type of datasets\n",
    "datasets_types = \"NUMERIC\"\n",
    "\n",
    "#  index column that need to be remove\n",
    "#  Assign None to id_column means no id column\n",
    "#  Remember minus 1 to obtain the correct index\n",
    "\n",
    "id_column = 0\n",
    "\n",
    "#  Enter the column number of class here\n",
    "#  Remember minus 1 to obtain the correct index\n",
    "class_column = 1\n",
    "\n",
    "#  Enter Missing value here\n",
    "missing_values = None\n",
    "\n",
    "#  Enter dataset here (name only)\n",
    "train_data = preprocess(wdbc, missing_values,id_column)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "# Only works when dataset_types equals MIX\n",
    "feature_types = [2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0]\n",
    "\n",
    "EPSILON = 1/(2*train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hold_out\n",
    "def separate_data(data):\n",
    "    X_train = data.sample(frac = 0.8, random_state = 123)\n",
    "    X_test  = data.drop(index = X_train.index)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% adult dataset(after hold out)\n",
      "correct 538 546\n",
      "{'correct_rate': 0.9853479853479854}\n",
      "Accuracy for 20% adult train dataset(after hold out)\n",
      "correct 136 137\n",
      "{'correct_rate': 0.9927007299270073}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = 0\n",
    "class_column = 10\n",
    "missing_values = '?'\n",
    "train_data = preprocess(breast_cancer_wisconsin, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "brest_train,brest_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% adult dataset(after hold out)\")\n",
    "print(calc_outcome(brest_train))\n",
    "print(\"Accuracy for 20% adult train dataset(after hold out)\")\n",
    "print(calc_outcome(brest_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% mushroom dataset (after hold out):\n",
      "correct 4441 4515\n",
      "{'correct_rate': 0.983610188261351}\n",
      "Accuracy for 20% mushroom dataset(after hold out)\n",
      "correct 1109 1129\n",
      "{'correct_rate': 0.9822852081488043}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = '?'\n",
    "train_data = preprocess(mushroom, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "mushroom_train,mushroom_test = separate_data(train_data,)\n",
    "print(\"Accuracy for 80% mushroom dataset (after hold out):\")\n",
    "print(calc_outcome(mushroom_train))\n",
    "print(\"Accuracy for 20% mushroom dataset(after hold out)\")\n",
    "print(calc_outcome(mushroom_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% lymphography dataset (after hold out):\n",
      "correct 96 118\n",
      "{'correct_rate': 0.8135593220338984}\n",
      "Accuracy for 20% lymphography dataset (after hold out):\n",
      "correct 27 30\n",
      "{'correct_rate': 0.9}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NOMINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(lymphography, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "lymphography_train,lymphography_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% lymphography dataset (after hold out):\")\n",
    "print(calc_outcome(lymphography_train))\n",
    "print(\"Accuracy for 20% lymphography dataset (after hold out):\")\n",
    "print(calc_outcome(lymphography_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% wdbc dataset (after hold out):\n",
      "correct 142 142\n",
      "{'correct_rate': 1.0}\n",
      "Accuracy for 20% wdbc dataset (after hold out):\n",
      "correct 36 36\n",
      "{'correct_rate': 1.0}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NUMERIC\"\n",
    "id_column = 0\n",
    "class_column = 1\n",
    "missing_values = None\n",
    "train_data = preprocess(wdbc, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "wdbc_train,wdbc_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% wdbc dataset (after hold out):\")\n",
    "print(calc_outcome(wine_train))\n",
    "print(\"Accuracy for 20% wdbc dataset (after hold out):\")\n",
    "print(calc_outcome(wine_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% wine dataset (after hold out):\n",
      "correct 139 142\n",
      "{'correct_rate': 0.9788732394366197}\n",
      "Accuracy for 20% wine dataset (after hold out):\n",
      "correct 36 36\n",
      "{'correct_rate': 1.0}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"NUMERIC\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(wine, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "wine_train,wine_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% wine dataset (after hold out):\")\n",
    "print(calc_outcome(wine_train))\n",
    "print(\"Accuracy for 20% wine dataset (after hold out):\")\n",
    "print(calc_outcome(wine_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% car dataset(after hold out)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-001232148a0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcar_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcar_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 80% car dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 20% car train dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-90090c910051>\u001b[0m in \u001b[0;36mcalc_outcome\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This function could quickly calculate the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2615c067e24c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NUMERIC\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatasets_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MIX\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mfind_numerical_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mfind_nominal_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eac500be46a3>\u001b[0m in \u001b[0;36mfind_numerical_llh\u001b[0;34m(attributes, llh_dict, data, feature)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 5\n",
    "missing_values = None\n",
    "train_data = preprocess(car, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "car_train,car_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% car dataset(after hold out)\")\n",
    "print(calc_outcome(car_train))\n",
    "print(\"Accuracy for 20% car train dataset(after hold out)\")\n",
    "print(calc_outcome(car_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% nursery dataset(after hold out)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 10",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-7dc61fda1a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnursery_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnursery_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 80% nursery dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnursery_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 20% nursery train dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnursery_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-90090c910051>\u001b[0m in \u001b[0;36mcalc_outcome\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This function could quickly calculate the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2615c067e24c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfind_numerical_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mfind_nominal_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5f252f7bc53e>\u001b[0m in \u001b[0;36mfind_nominal_llh\u001b[0;34m(attributes, llh_dict, data, feature_row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_nominal_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 8\n",
    "missing_values = None\n",
    "train_data = preprocess(nursery, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "nursery_train,nursery_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% nursery dataset(after hold out)\")\n",
    "print(calc_outcome(nursery_train))\n",
    "print(\"Accuracy for 20% nursery train dataset(after hold out)\")\n",
    "print(calc_outcome(nursery_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% somerville dataset(after hold out)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-14f538c9bc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msomerville_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msomerville_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseparate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 80% somerville dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msomerville_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for 20% somerville train dataset(after hold out)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msomerville_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-90090c910051>\u001b[0m in \u001b[0;36mcalc_outcome\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This function could quickly calculate the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdata_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_llh_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2615c067e24c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfind_numerical_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mfind_nominal_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5f252f7bc53e>\u001b[0m in \u001b[0;36mfind_nominal_llh\u001b[0;34m(attributes, llh_dict, data, feature_row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_nominal_llh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllh_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "datasets_types = \"ORDINAL\"\n",
    "id_column = None\n",
    "class_column = 0\n",
    "missing_values = None\n",
    "train_data = preprocess(somerville, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "somerville_train,somerville_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% somerville dataset(after hold out)\")\n",
    "print(calc_outcome(somerville_train))\n",
    "print(\"Accuracy for 20% somerville train dataset(after hold out)\")\n",
    "print(calc_outcome(somerville_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% somerville dataset(after hold out)\n",
      "correct 19867 24130\n",
      "{'correct_rate': 0.8233319519270618}\n",
      "Accuracy for 20% somerville train dataset(after hold out)\n",
      "correct 4946 6032\n",
      "{'correct_rate': 0.8199602122015915}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"MIX\"\n",
    "id_column = None\n",
    "class_column = 14\n",
    "missing_values = '?'\n",
    "train_data = preprocess(adult, missing_values,id_column)\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "\n",
    "adult_train,adult_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% somerville dataset(after hold out)\")\n",
    "print(calc_outcome(adult_train))\n",
    "print(\"Accuracy for 20% somerville train dataset(after hold out)\")\n",
    "print(calc_outcome(adult_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80% bank dataset(after hold out)\n",
      "correct 31322 36169\n",
      "{'correct_rate': 0.8659902126130111}\n",
      "Accuracy for 20% bank train dataset(after hold out)\n",
      "correct 7913 9042\n",
      "{'correct_rate': 0.8751382437513824}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "datasets_types = \"MIX\"\n",
    "id_column = None\n",
    "class_column = 14\n",
    "missing_values = None\n",
    "train_data = preprocess(bank, missing_values,id_column)\n",
    "feature_types = [2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0]\n",
    "\n",
    "bank_train,bank_test = separate_data(train_data)\n",
    "print(\"Accuracy for 80% bank dataset(after hold out)\")\n",
    "print(calc_outcome(bank_train))\n",
    "print(\"Accuracy for 20% bank train dataset(after hold out)\")\n",
    "print(calc_outcome(bank_test))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
