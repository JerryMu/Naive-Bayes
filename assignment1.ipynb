{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2020 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Classifiers\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 20 Apr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):**    `PLEASE ENTER YOUR NAME(S) HERE`\n",
    "\n",
    "**Student ID(s):**     `PLEASE ENTER YOUR ID(S) HERE`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from copy import copy, deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    read all datasets \n",
    "adult = pd.read_csv(\"datasets/adult.data\", header = None)\n",
    "bank = pd.read_csv(\"datasets/bank.data\", header = None)\n",
    "breast_cancer_wisconsin = pd.read_csv(\"datasets/breast-cancer-wisconsin.data\", header = None)\n",
    "car = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "lymphography = pd.read_csv(\"datasets/lymphography.data\", header = None)\n",
    "mushroom = pd.read_csv(\"datasets/mushroom.data\", header = None)\n",
    "nursery = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "somerville = pd.read_csv(\"datasets/somerville.data\", header = None)\n",
    "university = pd.read_csv(\"datasets/university.data\", header = None)\n",
    "wdbc = pd.read_csv(\"datasets/wdbc.data\", header = None)\n",
    "wine = pd.read_csv(\"datasets/wine.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function that delete all missing values\n",
    "def delete_missing_value(raw_dataset, missing_values):\n",
    "    rows = set(raw_dataset[raw_dataset.values == missing_values].index)\n",
    "    data = raw_dataset.drop(index = rows)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#    This function should prepare the data by reading it from a file and\n",
    "#    converting it into a useful format for training and testing\n",
    "\n",
    "def preprocess(df, missing_values):\n",
    "#     train=df.sample(frac=0.8,random_state=200)\n",
    "#     test=df.drop(train.index)\n",
    "#     Delete all missing values\n",
    "    train = delete_missing_value(df, missing_values)\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape =====> (5644, 23)\n",
      "======================================================\n",
      "EPSILON ========> 8.858965272856131e-05\n",
      "======================================================\n",
      "Some Data Examples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6  7  8  9  ... 13 14 15 16 17 18 19 20 21 22\n",
       "0  p  x  s  n  t  p  f  c  n  k ...  s  w  w  p  w  o  p  k  s  u\n",
       "1  e  x  s  y  t  a  f  c  b  k ...  s  w  w  p  w  o  p  n  n  g\n",
       "2  e  b  s  w  t  l  f  c  b  n ...  s  w  w  p  w  o  p  n  n  m\n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Data Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     object\n",
       "1     object\n",
       "2     object\n",
       "3     object\n",
       "4     object\n",
       "5     object\n",
       "6     object\n",
       "7     object\n",
       "8     object\n",
       "9     object\n",
       "10    object\n",
       "11    object\n",
       "12    object\n",
       "13    object\n",
       "14    object\n",
       "15    object\n",
       "16    object\n",
       "17    object\n",
       "18    object\n",
       "19    object\n",
       "20    object\n",
       "21    object\n",
       "22    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global Variable\n",
    "\n",
    "#  Enter dataset here\n",
    "missing_values = '?'\n",
    "train_data = preprocess(mushroom, missing_values)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "datasets_types = \"NOMINAL\"\n",
    "\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "class_column = 0\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# 分开label和数据\n",
    "label = train_data.iloc[:,class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "# Show some useful information about the data\n",
    "print(\"Data Shape =====>\", train_data.shape)\n",
    "print(\"======================================================\")\n",
    "print(\"EPSILON ========>\", EPSILON)\n",
    "print(\"======================================================\")\n",
    "print(\"Some Data Examples:\")\n",
    "display(train_data.head(3))\n",
    "print(\"======================================================\")\n",
    "print(\"Data Type:\")\n",
    "display(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate prior\n",
    "def find_nominal_prob(class_column):\n",
    "    prior = {}\n",
    "    total_number = len(class_column)\n",
    "    classes = class_column.value_counts()\n",
    "    for key in classes.keys():\n",
    "        prior[key] = math.log2(classes[key]/total_number)\n",
    "    return prior\n",
    "\n",
    "#Tutor版本:\n",
    "def nominal_prob(series,denom,n_keys,k=0): \n",
    "    prior = {}\n",
    "    counts = series.value_counts()\n",
    "    keys = list(counts.keys())\n",
    "    for key in keys: \n",
    "        prior[key] = np.log2((counts[key]+k)/(denom+k*n_keys)) \n",
    "    return prior \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{36: -5.18028575254781, 31: -5.196441520938851, 34: -5.1996944987339395, 23: -5.214424354844224, 35: -5.216070327687784, 33: -5.217718180569267, 28: -5.230969204067122, 30: -5.240987959892114, 37: -5.246023549789411, 25: -5.274895397033813, 27: -5.285224999927543, 32: -5.297370429789632, 38: -5.299113868117683, 39: -5.318432045317462, 29: -5.32374584521393, 41: -5.332645904537163, 24: -5.3506124510666115, 40: -5.357862190145999, 26: -5.374308543509968, 42: -5.383527073539347, 43: -5.402142751706694, 22: -5.411541449708944, 20: -5.434351332617029, 46: -5.465336578193888, 45: -5.471221134445745, 44: -5.491011500205753, 21: -5.499004290959283, 19: -5.51512395632256, 47: -5.52325183720596, 50: -5.757237710529256, 51: -5.774111529093652, 49: -5.818429878643475, 18: -5.887569578876936, 48: -5.906048999484596, 52: -6.089990579308209, 53: -6.132876392161386, 55: -6.280050953589606, 54: -6.29388986105467, 17: -6.365148544224493, 58: -6.475157549004915, 56: -6.475157549004915, 57: -6.507041610024701, 59: -6.5191821728969135, 60: -6.70545516842671, 61: -6.762038696793076, 62: -6.9796301318657035, 63: -7.145367336344583, 64: -7.290417669147866, 65: -7.51512395632256, 67: -7.752452647963879, 66: -7.762038696793076, 68: -8.083966791680439, 69: -8.235969885125488, 70: -8.51512395632256, 71: -8.820932385846644, 72: -8.924768196831184, 73: -8.990857387288958, 74: -9.318432045317461, 76: -9.467295431231944, 75: -9.499004290959283, 90: -9.56459263258686, 77: -10.132876392161386, 78: -10.467295431231944, 80: -10.53142576865166, 79: -10.53142576865166, 81: -10.668929292401595, 82: -11.4058948865678, 84: -11.668929292401595, 83: -12.4058948865678, 85: -13.4058948865678, 88: -13.4058948865678, 87: -14.990857387288958, 86: -14.990857387288958}\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior\n",
    "print(find_nominal_prob(adult[class_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nominal_llh(attributes, llh_dict, data, feature_row):\n",
    "    all_feature = data[feature_row].value_counts()\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature_row:{}}\n",
    "        subset = data[data[class_column] == attribute][feature_row]\n",
    "        feature_dict[feature_row] = find_nominal_prob(subset)\n",
    "        for check_feature in all_feature.keys():\n",
    "            if check_feature not in feature_dict[feature_row].keys():\n",
    "                feature_dict[feature_row][check_feature] = np.log2(EPSILON)\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "            \n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_numerical_llh(attributes, llh_dict, data, feature):\n",
    "#  Save mean and Std as llh\n",
    "    for attribute in attributes:\n",
    "        feature_dict = {feature:{}}\n",
    "        subset = subset = data[data[class_column] == attribute][feature]\n",
    "        mean = np.mean(subset)\n",
    "        std = np.std(subset)\n",
    "        feature_dict[feature][\"mean\"] = mean\n",
    "        feature_dict[feature][\"std\"] = std\n",
    "        if(llh_dict[attribute]):\n",
    "            llh_dict[attribute].update(feature_dict)\n",
    "        else:\n",
    "            llh_dict[attribute] = feature_dict\n",
    "    return llh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function should calculat prior probabilities and likelihoods from the training data\n",
    "#  and using them to build a naive Bayes model\n",
    "\n",
    "def train(data):\n",
    "    prior = find_nominal_prob(data[class_column])\n",
    "    llh_dict = dict.fromkeys(prior)\n",
    "    for i in feature_columns:\n",
    "        if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "            find_numerical_llh(prior, llh_dict, data, i)\n",
    "        else:\n",
    "            find_nominal_llh(prior, llh_dict, data, i)\n",
    "            \n",
    "    return prior, llh_dict\n",
    "\n",
    "prior, llh_dict = train(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you\n",
    "# can re-use the training data as a test set)\n",
    "\n",
    "def predict(instance, prior, llh_dict):\n",
    "    all_prob = {}\n",
    "    for attribute in prior.keys():\n",
    "        all_prob[attribute] = prior[attribute]\n",
    "        for i in feature_columns:\n",
    "            prob = 0\n",
    "            if(datasets_types == \"NUMERIC\" or (datasets_types == \"MIX\" and feature_types[i] == 2)):\n",
    "                mean = max(llh_dict[attribute][i][\"mean\"], 1 * 10 ** -8)\n",
    "                std = max(llh_dict[attribute][i][\"std\"], 1 * 10 ** -8)\n",
    "                prob = stats.norm.pdf(x=instance[i], loc=mean, scale=std)\n",
    "                if prob > 0.0:\n",
    "                    prob = np.log2(prob)\n",
    "                else:\n",
    "                    prob = np.log2(1 * 10 ** -8)\n",
    "            else:\n",
    "                prob = llh_dict[attribute][i][instance[i]]\n",
    "            all_prob[attribute] += prob\n",
    "    max_prob = -10000\n",
    "    max_key = \"\"\n",
    "    \n",
    "    for prob in all_prob.keys():\n",
    "        if(all_prob[prob] > max_prob):\n",
    "            max_prob = all_prob[prob]\n",
    "            max_key = prob\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(train_data.iloc[0], prior, llh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Overall Accuracy is: \n",
      "correct 5592 5644\n",
      "{'correct_rate': 0.9907866761162296}\n"
     ]
    }
   ],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels\n",
    "\n",
    "def evaluate(data, prior, llh_dict, interesting_class = None):\n",
    "    predict_list = []\n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "    result = {}\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        actual_class = row[class_column]\n",
    "        predict_class = predict(row, prior, llh_dict)\n",
    "        if (actual_class == predict_class):\n",
    "            correct += 1\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    TP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    TN += 1\n",
    "        else:\n",
    "            if interesting_class:\n",
    "                if(interesting_class == row[class_column]):\n",
    "                    FP += 1\n",
    "                elif(interesting_class != row[class_column]):\n",
    "                    FN += 1\n",
    "                    \n",
    "    correct_rate = correct/total\n",
    "    result[\"correct_rate\"] = correct_rate\n",
    "    \n",
    "    if (interesting_class):\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        result[\"precision\"] = precision\n",
    "        result[\"recall\"] = recall\n",
    "    print(\"correct\",correct,total)\n",
    "    return result\n",
    "# %time\n",
    "print(\"======================================================\")\n",
    "print(\"Overall Accuracy is: \")\n",
    "print(evaluate(train_data, prior, llh_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to question (1), and **one** other of your choosing (two responses in total).\n",
    "\n",
    "If you are in a group of 2, you will respond to question (1) and question (2), and **two** others of your choosing (four responses in total). \n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions in respond to the question, but your formal answer should be added to a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Try discretising the numeric attributes in these datasets and treating them as discrete variables in the na¨ıve Bayes classifier. You can use a discretisation method of your choice and group the numeric values into any number of levels (but around 3 to 5 levels would probably be a good starting point). Does discretizing the variables improve classification performance, compared to the Gaussian na¨ıve Bayes approach? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use adult dataset for this question\n",
    "missing_values = '?'\n",
    "train_data = preprocess(adult, missing_values)\n",
    "\n",
    "'''\n",
    "    datasets_types can be \n",
    "    NOMINAL: NOMINAL ATTRIBUTES DATASETS, \n",
    "    NUMERIC: NUMERIC ATTRIBUTES DATASETS, \n",
    "    ORDINAL: ORDINAL ATTRIBUTES DATASETS, \n",
    "    MIX: DATASETS WITH A MIX OF ATTRIBUTE TYPES\n",
    "'''\n",
    "datasets_types = \"MIX\"\n",
    "\n",
    "# 0 represents nomianl, 1 represents ordinal, 2 represents numeric\n",
    "feature_types = [2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0]\n",
    "class_column = 14\n",
    "EPSILON = 1/(2*train_data.shape[0])\n",
    "\n",
    "# 分开label和数据\n",
    "label = train_data.iloc[:,class_column]\n",
    "train_set = train_data.drop(columns=class_column)\n",
    "\n",
    "feature_columns = list(train_set.columns)\n",
    "\n",
    "\n",
    "def discretise(data,data_type,levels,by):\n",
    "    #给定一个数据集及其对应的数据类型，\n",
    "    #必须将其所有数字特征离散为离散特征，\n",
    "    #'宽度' & '频率'\n",
    "    #代表等宽或者等频率并且取一个可靠的整数，\n",
    "    #然后确定离散后的特征级别的总数\n",
    "    copy_data = data.copy()\n",
    "    discrete_datatype = data_type.copy()\n",
    "    for i in range(len(data_type)):\n",
    "        # 找出所有的 Numeric Data,然后组成新的DataFrame\n",
    "        # Note: 2 means numeric data type\n",
    "        if data_type[i] == 2: # continuous\n",
    "            feature = data.iloc[:,i]\n",
    "            copy_feature = feature.copy()\n",
    "            \n",
    "            # Equal Width\n",
    "            if by=='width':\n",
    "                # calculate width of each level\n",
    "                maximum = np.max(feature)\n",
    "                minimum = np.min(feature)\n",
    "                width = (maximum-minimum)/levels # width of each level\n",
    "                for j in range(levels):\n",
    "                    copy_feature[feature<=(maximum-width*j)] = ('level'+str(levels-j))\n",
    "           \n",
    "            # Equal Quantile\n",
    "            else:\n",
    "                frequency = feature.shape[0]/levels # frequency of each level\n",
    "                for m in range(levels):\n",
    "                    lower = int(frequency*m) # lower bound of index, so has to be integer\n",
    "                    upper = int(frequency*(m+1)) # upper bound of index, so has to be integer\n",
    "                    copy_feature[feature.sort_values()[lower:upper].index] = ('level'+str(levels-m))\n",
    "            copy_data.iloc[:,i] = copy_feature\n",
    "            discrete_datatype[i] = 1 \n",
    "    return copy_data,discrete_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "======================================================\n",
      "Equal Width:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "level1    29930\n",
       "level5      148\n",
       "level2       82\n",
       "level3        2\n",
       "Name: 10, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "Equal Frequency:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "level1    6033\n",
       "level3    6033\n",
       "level4    6032\n",
       "level2    6032\n",
       "level5    6032\n",
       "Name: 10, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width_data,discrete_datatype = discretise(train_data,feature_types,levels=5,by='width')\n",
    "freq_data,discrete_datatype = discretise(train_data,feature_types,levels=5,by='freq')\n",
    "print(discrete_datatype)\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Width:\")\n",
    "display(width_data.iloc[:,10].value_counts())\n",
    "print(\"======================================================\")\n",
    "print(\"Equal Frequency:\")\n",
    "display(freq_data.iloc[:,10].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>level2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>level1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>level2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>level3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>level1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>level2</td>\n",
       "      <td>Private</td>\n",
       "      <td>level1</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>level2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>level3</td>\n",
       "      <td>Private</td>\n",
       "      <td>level1</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>level2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>level1</td>\n",
       "      <td>Private</td>\n",
       "      <td>level2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>level1</td>\n",
       "      <td>level1</td>\n",
       "      <td>level2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                 1       2          3   4                   5   \\\n",
       "0  level2         State-gov  level1  Bachelors  13       Never-married   \n",
       "1  level3  Self-emp-not-inc  level1  Bachelors  13  Married-civ-spouse   \n",
       "2  level2           Private  level1    HS-grad   9            Divorced   \n",
       "3  level3           Private  level1       11th   7  Married-civ-spouse   \n",
       "4  level1           Private  level2  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9       10      11      12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  level1  level1  level2   \n",
       "1    Exec-managerial        Husband  White    Male  level1  level1  level1   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male  level1  level1  level2   \n",
       "3  Handlers-cleaners        Husband  Black    Male  level1  level1  level2   \n",
       "4     Prof-specialty           Wife  Black  Female  level1  level1  level2   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "level1    26380\n",
       "level2     3652\n",
       "level3      111\n",
       "level4       14\n",
       "level5        5\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(width_data.head(5))\n",
    "width_data[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 24524 30162\n",
      "{'correct_rate': 0.8130760559644586}\n"
     ]
    }
   ],
   "source": [
    "feature_types = discrete_datatype\n",
    "width_prior, width_llh_dict = train(width_data)\n",
    "width_eval = evaluate(width_data, width_prior, width_llh_dict)\n",
    "print(width_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 24439 30162\n",
      "{'correct_rate': 0.810257940454877}\n"
     ]
    }
   ],
   "source": [
    "freq_prior, freq_llh_dict = train(freq_data)\n",
    "freq_eval = evaluate(freq_data, freq_prior, freq_llh_dict)\n",
    "print(freq_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Implement a baseline model (e.g., random or 0R) and compare the performance of the na¨ıve Bayes classifier to this baseline on multiple datasets. Discuss why the baseline performance varies across datasets, and to what extent the na¨ıve Bayes classifier improves on the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_r_evaluate(data,label_index):\n",
    "    temp_data = data.copy()\n",
    "    zero_r_result = temp_data[label_index].value_counts().idxmax()\n",
    "\n",
    "    series_of_class = temp_data[label_index]\n",
    "    list_of_class = series_of_class.values.tolist()\n",
    "    \n",
    "    correct = 0\n",
    "    total = data.shape[0]\n",
    "\n",
    "    for i in range(len(list_of_class)):\n",
    "        if zero_r_result == list_of_class[i]:\n",
    "            correct += 1\n",
    "    correct_rate = correct / total\n",
    "    \n",
    "    return correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some 0R baseline model for varius dataset:\n",
      "\n",
      "0R baseline model performance for ADULT dataset:\n",
      "0.7510775147536636\n",
      "======================================================\n",
      "0R baseline model performance for MUSHROOM dataset:\n",
      "0.5556343019135365\n",
      "======================================================\n",
      "0R baseline model performance for BANK dataset:\n",
      "0.8830151954170445\n",
      "======================================================\n",
      "0R baseline model performance for WINE dataset:\n",
      "0.398876404494382\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Some 0R baseline model for varius dataset:\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"0R baseline model performance for ADULT dataset:\")\n",
    "adult_0R_data = preprocess(adult,\"?\") \n",
    "print(zero_r_evaluate(adult_0R_data,14))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for MUSHROOM dataset:\")\n",
    "mushroom_0R_data = preprocess(mushroom,\"?\") \n",
    "print(zero_r_evaluate(mushroom_0R_data,14))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for BANK dataset:\")\n",
    "bank_0R_data = preprocess(bank,None) \n",
    "print(zero_r_evaluate(bank_0R_data,14))\n",
    "print(\"======================================================\")\n",
    "\n",
    "print(\"0R baseline model performance for WINE dataset:\")\n",
    "wine_0R_data = preprocess(wine,None) \n",
    "print(zero_r_evaluate(wine_0R_data,0))\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Since it’s difficult to model the probabilities of ordinal data, ordinal attributes are often treated as either nominal variables or numeric variables. Compare these strategies on the ordinal datasets provided. Deterimine which approach gives higher classification accuracy and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc\n",
       "5  vhigh  vhigh  2  2    med  high  unacc\n",
       "6  vhigh  vhigh  2  2    big   low  unacc\n",
       "7  vhigh  vhigh  2  2    big   med  unacc\n",
       "8  vhigh  vhigh  2  2    big  high  unacc\n",
       "9  vhigh  vhigh  2  4  small   low  unacc"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use car dataset for this question\n",
    "car.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 1511 1729\n",
      "{'correct_rate': 0.8739155581260845}\n",
      "correct 1098 1729\n",
      "{'correct_rate': 0.6350491613649508}\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/21818886/changing-ordinal-character-data-to-numeric-data-with-pandas\n",
    "car_origin = pd.read_csv(\"datasets/car.data\", header = None)\n",
    "car = car_origin.copy()\n",
    "buying_conv_dict= {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[0]=car[0].apply(buying_conv_dict.get)\n",
    "maint_conv_dict = {'low':0,'med':1,'high':2,'vhigh':3}\n",
    "car[1]=car[1].apply(maint_conv_dict.get)\n",
    "doors_conv_dict = {'2':1, '3':2, '4':3, '5more': 4}\n",
    "car[2]=car[2].apply(doors_conv_dict.get)\n",
    "persons_conv_dict = {'2':0, '4':1, 'more':2}\n",
    "car[3]=car[3].apply(persons_conv_dict.get)\n",
    "lug_boot_conv_dict = {'small':0,'med':1, 'big':2}\n",
    "car[4]=car[4].apply(lug_boot_conv_dict.get)\n",
    "safety_conv_dict = {'low':0 , 'med':1, 'high':2}\n",
    "car[5]=car[5].apply(safety_conv_dict.get)\n",
    "class_conv_dict = {'unacc':0 , 'acc':1, 'good':2, 'vgood':3}\n",
    "car[6]=car[6].apply(class_conv_dict.get)\n",
    "\n",
    "#nominal \n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 6\n",
    "label = car_origin.iloc[:,class_column]\n",
    "train_set = car_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "prior, llh_dict = train(car_origin)\n",
    "print(evaluate(car_origin, prior, llh_dict))\n",
    "\n",
    "#numercial \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 6\n",
    "prior, llh_dict = train(car)\n",
    "print(evaluate(car, prior, llh_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>inconv</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>very_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1         2  3           4           5              6  \\\n",
       "0  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "1  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "2  usual  proper  complete  1  convenient  convenient        nonprob   \n",
       "3  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "4  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "5  usual  proper  complete  1  convenient  convenient  slightly_prob   \n",
       "6  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "7  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "8  usual  proper  complete  1  convenient  convenient    problematic   \n",
       "9  usual  proper  complete  1  convenient      inconv        nonprob   \n",
       "\n",
       "             7           8  \n",
       "0  recommended   recommend  \n",
       "1     priority    priority  \n",
       "2    not_recom   not_recom  \n",
       "3  recommended   recommend  \n",
       "4     priority    priority  \n",
       "5    not_recom   not_recom  \n",
       "6  recommended    priority  \n",
       "7     priority    priority  \n",
       "8    not_recom   not_recom  \n",
       "9  recommended  very_recom  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nursery.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 11704 12960\n",
      "{'correct_rate': 0.9030864197530865}\n",
      "correct 8201 12960\n",
      "{'correct_rate': 0.6327932098765432}\n"
     ]
    }
   ],
   "source": [
    "nursery_origin = pd.read_csv(\"datasets/nursery.data\", header = None)\n",
    "\n",
    "nursery_numeric = nursery_origin.copy()\n",
    "\n",
    "parents_dict = {'usual':0, 'pretentious':1, 'great_pret':2}\n",
    "nursery_numeric[0]=nursery_numeric[0].apply(parents_dict.get)\n",
    "has_nurs_dict ={'proper':0, 'less_proper':1, 'improper':2, 'critical':3, 'very_crit':4}\n",
    "nursery_numeric[1]=nursery_numeric[1].apply(has_nurs_dict.get)\n",
    "form_dict = {'complete':0, 'completed':1, 'incomplete':2, 'foster':3}\n",
    "nursery_numeric[2]=nursery_numeric[2].apply(form_dict.get)\n",
    "children_dict ={'1':0, '2':1, '3':2, 'more':3}\n",
    "nursery_numeric[3]=nursery_numeric[3].apply(children_dict.get)\n",
    "housing_dict = {'convenient':0, 'less_conv':1, 'critical':2}\n",
    "nursery_numeric[4]=nursery_numeric[4].apply(housing_dict.get)\n",
    "finance_dict = {'convenient':0, 'inconv':1}\n",
    "nursery_numeric[5]=nursery_numeric[5].apply(finance_dict.get)\n",
    "social_dict = {'nonprob':0, 'slightly_prob':1, 'problematic':2}\n",
    "nursery_numeric[6]=nursery_numeric[6].apply(social_dict.get)\n",
    "health_dict = {'recommended':0, 'priority':1, 'not_recom':2}\n",
    "nursery_numeric[7]=nursery_numeric[7].apply(health_dict.get)\n",
    "class_dict = {'not_recom':0, 'recommend':1, 'very_recom':2, 'priority':3, 'spec_prior':4}\n",
    "nursery_numeric[8]=nursery_numeric[8].apply(class_dict.get)\n",
    "\n",
    "#nominal \n",
    "datasets_types = \"NOMINAL\"\n",
    "class_column = 8\n",
    "label = nursery_origin.iloc[:,class_column]\n",
    "train_set = nursery_origin.drop(columns=class_column)\n",
    "feature_columns = list(train_set.columns)\n",
    "prior, llh_dict = train(nursery_origin)\n",
    "print(evaluate(nursery_origin, prior, llh_dict))\n",
    "\n",
    "#numercial \n",
    "datasets_types = \"NUMERIC\"\n",
    "class_column = 8\n",
    "prior, llh_dict = train(nursery_numeric)\n",
    "print(evaluate(nursery_numeric, prior, llh_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out or cross–validation evaluation strategy (you should implement this yourself and do not simply call existing implementations from `scikit-learn`). How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Implement one of the advanced smoothing regimes (add-k, Good-Turing). Does changing the smoothing regime (or indeed, not smoothing at all) affect the effectiveness of the na¨ıve Bayes classifier? Explain why, or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "The Gaussian na¨ıve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in these datasets? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the NB classifier’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
